---
title: "p8105_hw2_bg2604"
author: "Boya Guo"
date: "10/5/2018"
output: github_document
---

```{r}
library(tidyverse)
library(readxl)
library(knitr)
```

```{r}
knitr::opts_chunk$set((echo = TRUE),
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```

## Problem 1 NYC Transit 

1.1 Import NYC transit csv file usirng relative path, and clean the dataset.  

```{r 1.1}
transit_data = read_csv(file="./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")%>%
  janitor::clean_names() %>% 
  gather(key = route_number, value=route_name,route1:route11)%>%
  separate(route_number, into = c("route", "route_number"), sep = 5) %>%
  filter(!is.na(route_name))%>%
  select(line, station_name, station_latitude, station_longitude, route_number,route_name, entry, vending, entrance_type, ada)%>%
  mutate(entry=ifelse(entry=='YES',yes=TRUE,no=FALSE))%>%
  arrange(line,station_name)
```

The NYC transit dataset contains: 
Division, line, station names, station and entrance locations, routes in each station, differnet trains for each route in station, whether the station allows entrance or vending, entrance type, staffs, free crossover, North South and East West streets and corners,and ADA compliance.

Cleaning steps: 

With the understanding of dataset, I noticed that the routes is speard across 11 columns. I used the "gather" function to transpose. Then, I used "seperate" function to split the "route_number" column into "route"
and "route_number". After that, I used "filter" function to only detect observations with non-missing "route_name". I used "select" function to retain the variables I need, and converted the "entry"" variable from character to a logical variable. For the last step, I arranged the dataset by "line"" and "station_name". 

The dimension of this dataset is `r nrow(transit_data)` by `r ncol(transit_data)` dataset.

These data are tidy.


1.2 Distinct stations, stations are ADA compliant, and porportion of station entrances/exits without vending entrance  

```{r 1.2}
distinct_station = nrow(distinct(transit_data,station_name,line,.keep_all = TRUE))
distinct_station 

ada_compliance = transit_data %>% 
  filter(ada == TRUE) %>% 
  distinct(station_name,line)
nrow(ada_compliance)

allow_entrance = transit_data %>% 
  filter(entry==TRUE & vending == 'NO') %>% 
  distinct(line,station_name)

vending = transit_data %>% 
  filter(vending == 'NO') %>% 
  distinct(line,station_name)
proportion = nrow(allow_entrance)/nrow(vending)
proportion
```
There are 465 distinct stations, 84 are ADA compliant, and 43% of station entrances/exists without vending allow entrance. 

1.3 Distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?

```{r 1.3}
a_train = transit_data %>% 
  filter(route_name=='A') %>% 
  distinct(station_name,line)
nrow(a_train)

a_ada = transit_data %>% 
  filter(route_name=='A' & ada==TRUE) %>% 
  distinct(station_name,line)
nrow(a_ada)
```

There are 60 distinct stations serve the A train; of the stations that serve the A train, 17 are ADA compliant.

## Problem 2 Mr Trash Wheel 

Read and clean dataset

```{r 2.1}
trash = read_excel(path = './data/HealthyHarborWaterWheelTotals2018-7-28.xlsx',sheet = 'Mr. Trash Wheel',range = cell_cols("A:N"))%>%
  janitor::clean_names()%>%
  filter(!is.na(date))%>%
  mutate(sports_balls=as.integer(signif(sports_balls)))
```

Read and clean precipitation data for 2016 and 2017

```{r}
pre_2016 = read_excel(path = './data/HealthyHarborWaterWheelTotals2018-7-28.xlsx',sheet = '2016 Precipitation',range = cell_rows(2:14))%>%
  janitor::clean_names()%>%
  mutate(year=2016)

pre_2017 = read_excel(path = './data/HealthyHarborWaterWheelTotals2018-7-28.xlsx',sheet = '2017 Precipitation',range = cell_rows(2:14))%>%
  janitor::clean_names()%>%
  mutate(year=2017)

pre_1617=bind_rows(pre_2016,pre_2017)%>%
  janitor::clean_names()%>%
  select(year, everything())%>%
  mutate(month=month.name[month])
```

Mr.Trash Wheel dataset has `r nrow(trash)`
observations and the key variable is weight_tons.

The dataset for year 2016-2017 precipitation has `r nrow(pre_1617)` observations and the key variable is total precipitation for each month. 

The total precipitation in 2017 is `r sum(pre_2017$total)`.

The median number of sports balls in a dumpster in 2016 is `r trash %>% filter(year==2016,!is.na(sports_balls)) %>% pull(sports_balls) %>% median()`.

## Problem 3

Format and clean data 

```{r 3.1}
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
brfsm=brfss_smart2010 %>% 
  janitor::clean_names() %>%
  separate(locationdesc, into = c("state", "county"), sep = " - ") %>%
  filter(topic=='Overall Health')%>%
  select(-class,-topic,-question,-sample_size,-locationabbr,-(confidence_limit_low:geo_location))%>%
  spread(key = response, value = data_value)%>%
  janitor::clean_names()%>%
  select(year,state,county,excellent,very_good,good,fair,poor)%>%
  mutate(above_good=excellent+very_good)
```

Answer questions 

```{r}
nrow(distinct(brfsm,state,county))

nrow(distinct(brfsm,state))

count(brfsm,state)%>%
  arrange(-n)%>%
  head(1)

brfsm%>%
  filter(year==2002, !is.na(excellent)) %>% 
  pull(excellent) %>% 
  median()

brfsm%>%
  filter(year==2002)%>%
  ggplot(aes(x = excellent))+ 
  geom_histogram()+
  labs(
    title = '"Excellent" response values in 2002',
    x = 'Proportion of "Excellent"'
  )

brfsm%>%
  filter(county =='New York County' | county == 'Queens County')%>%
  ggplot(aes(x = year, y = excellent))+ 
  geom_point(aes(color = county))+
  labs(
    title = '“Excellent” response in 2 counties',
    x = 'Proportion of "Excellent"'
  )
```

There are 404 unique locations are included in the dataset. 

All states are represented; NJ is the state observed the most.  

In 2002, the median of the “Excellent” response value is 23.6.
